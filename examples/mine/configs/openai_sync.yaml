out_root: out/how2mine

inputs:
  path: examples/mine/sample_data  # this is non-recursive; you can also set a file path directly
  include_globs: ["*.arrow"]
  format: auto
  compression: auto
  id_field: id
  text_field: text
  url_field: id
  topic_field: topic_top_choice

# topics is optional. If omitted (or set to []), the pipeline runs in no-topics mode:
# it processes all input records (up to targets.candidates_per_topic total) and writes `all.jsonl` per stage.
topics:
  - Art & Design
  - Crime & Law
  - Education & Jobs
  # - Electronics & Hardware
  # - Fashion & Beauty
  # - Food & Dining
  # - Health
  # - Home & Hobbies
  # - Industrial
  # - Religion
  # - Science, Math & Technology
  # - Sports & Fitness
  # - Transportation
  # - Travel & Tourism

llm:
  provider: openai
  model: gpt-4.1
  temperature: 0.0
  max_new_tokens: 4096
  # Concurrency/rate-limits are managed by lm-deluge.
  max_requests_per_minute: 10000
  max_tokens_per_minute: 1200000

prompts:
  procedures: prompts/extract_procedures.txt
  filter: prompts/filter.txt
  postprocess: prompts/postprocess.txt
  resources: prompts/extract_resources.txt
  final_filter: prompts/final_filter.txt

targets:
  candidates_per_topic: 1000       # max documents to extract per topic (the budget)
  desired_valid_per_topic: 30     # stop early once this many pass all stages per topic
  extract_batch_size: 100          # new candidates per topic per round

export:
  format: jsonl        # jsonl | jsonl_zst | parquet | arrow_ipc
  max_file_size: "500MB"   # optional; if omitted -> single file
